{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "using adam and 60 epoch with only 2 dense\n",
        "26 - Aug\n",
        "\n",
        "This is the best result we used for comparison.\n",
        "\n",
        "Previoous\n",
        "```\n",
        "Epoch 60/60\n",
        "2672/2672 - 68s - loss: 1.2386e-05 - mse: 1.2386e-05 - mae: 0.0016 - val_loss: 1.7205e-05 - val_mse: 1.7205e-05 - val_mae: 0.0020 - 68s/epoch - 25ms/step\n",
        "Elapsed time: 4124 seconds.\n",
        "```"
      ],
      "metadata": {
        "id": "RhuGHK_wxJDe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F45PApp4vkLQ"
      },
      "outputs": [],
      "source": [
        "#!/urs/bin/env python3\n",
        "\n",
        "\"\"\"\n",
        "Codes for loading and preprocessing the data.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "\n",
        "\n",
        "def load_data(filename, train_evo, test_evo, steps, window_size,\n",
        "              normalization='none'):\n",
        "    \"\"\"\n",
        "    Load data. Add input pulse profile as the first step.\n",
        "    The input for the network is 'window_size' times the input profile.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    filename : filename as string\n",
        "    train_evo : number of training evolutions as integer\n",
        "    test_evo : number of test evolutions as integer\n",
        "    steps : number of propagation steps as integer\n",
        "    window_size : RNN window size as integer\n",
        "    normalization : none (default), max, dBm, manual ...\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    i_x : number of grid points (spectral/temporal) as integer\n",
        "    X_train : training data input, shape (N, window_size, i_x)\n",
        "    X_test : testing data input, shape (M, window_size, i_x)\n",
        "    Y_train : training data output, shape (N, i_x)\n",
        "    Y_test : testing data output, shape (M, i_x)\n",
        "    \"\"\"\n",
        "\n",
        "    # Load data\n",
        "    mat_contents = sio.loadmat(filename)\n",
        "    data = mat_contents['data']\n",
        "    print(\"data loaded...\")\n",
        "    print(data.shape)\n",
        "\n",
        "    if normalization == 'none':\n",
        "        pass\n",
        "        \n",
        "    elif normalization == 'max':  # linear scale (normalized)\n",
        "        m_max = np.max(np.fabs(data))\n",
        "        print('max:', m_max)\n",
        "        data = data/m_max\n",
        "\n",
        "    elif normalization == 'dBm':  # logarithmic scale\n",
        "        m_max = np.max(np.fabs(data))\n",
        "        print('max:', m_max)\n",
        "        data=data/m_max  # normalize\n",
        "        data = 10*np.log10(data)  # dB scale\n",
        "        dBlim = 55  # define dynamic range\n",
        "        data[data < -dBlim] = -dBlim  # set spectrum <-55 to -55\n",
        "        data = data/dBlim + 1\n",
        "\n",
        "    elif normalization == 'manual':\n",
        "        m_max = 10369993.175721595 # SC spectral domain\n",
        "        print('max:', m_max)\n",
        "        data = data/m_max\n",
        "\n",
        "\n",
        "    # the number of grid points\n",
        "    i_x = data.shape[1]\n",
        "\n",
        "    # Make the time series\n",
        "    num_evo = train_evo + test_evo\n",
        "    evo_size = steps - 1\n",
        "    num_samples = np.round(num_evo*evo_size).astype(int)\n",
        "    X_data_series = np.zeros((num_samples, window_size, i_x))\n",
        "    Y_data_series = np.zeros((num_samples, i_x))\n",
        "\n",
        "    for evo in range(num_evo):\n",
        "        evo_data = np.transpose(data[evo, :, :])\n",
        "\n",
        "        # tile the beginning of the evolution with 'window_size' input profiles\n",
        "        temp1 = evo_data[0, :]\n",
        "        temp2 = np.tile(temp1, (window_size - 1, 1))\n",
        "        evo_data = np.vstack((temp2, evo_data))\n",
        "\n",
        "        for step in range(evo_size):\n",
        "            input_data = evo_data[step:step + window_size, :]\n",
        "            output_data = evo_data[step + window_size, :]\n",
        "            series_idx = evo*evo_size + step\n",
        "            X_data_series[series_idx, :, :] = input_data\n",
        "            Y_data_series[series_idx, :] = output_data\n",
        "\n",
        "\n",
        "    X_train = X_data_series[:num_samples - test_evo*evo_size]\n",
        "    X_test = X_data_series[num_samples - test_evo*evo_size:]\n",
        "    Y_train = Y_data_series[:num_samples - test_evo*evo_size]\n",
        "    Y_test = Y_data_series[num_samples - test_evo*evo_size:]\n",
        "\n",
        "    return i_x, X_train, X_test, Y_train, Y_test\n",
        "\n",
        "\n",
        "def load_data_expt(filename, train_evo, test_evo, steps, window_size,\n",
        "                   normalization='none'):\n",
        "    \"\"\"\n",
        "    Load data to predict the evolution from a given 'window_size' steps.\n",
        "    To be used with data sets \"HOS_expt_time_151\" and \"HOS_expt_spec_126\".\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    filename : filename as string\n",
        "    train_evo : number of training evolutions as integer\n",
        "    test_evo : number of test evolutions as integer\n",
        "    steps : number of propagation steps as integer\n",
        "    window_size : RNN window size as integer\n",
        "    normalization : none (default), max, manual ...\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    i_x : number of grid points (spectral/temporal) as integer\n",
        "    X_train : training data input, shape (N, window_size, i_x)\n",
        "    X_test : testing data input, shape (M, window_size, i_x)\n",
        "    Y_train : training data output, shape (N, i_x)\n",
        "    Y_test : testing data output, shape (M, i_x)\n",
        "    \"\"\"\n",
        "\n",
        "    # Load data\n",
        "    mat_contents = sio.loadmat(filename)\n",
        "    data = mat_contents['data']\n",
        "    print(\"data loaded...\")\n",
        "    print(data.shape)\n",
        "\n",
        "    if normalization == 'none':\n",
        "        pass\n",
        "\n",
        "    elif normalization == 'max':  # linear scale (normalized)\n",
        "        m_max = np.max(np.fabs(data))\n",
        "        print('max:', m_max)\n",
        "        data = data/m_max\n",
        "\n",
        "    elif normalization == 'dBm':  # logarithmic scale\n",
        "        m_max = np.max(np.fabs(data))\n",
        "        print('max:', m_max)\n",
        "        data=data/m_max  # normalize\n",
        "        data = 10*np.log10(data)  # dB scale\n",
        "        dBlim = 55  # define dynamic range\n",
        "        data[data < -dBlim] = -dBlim  # set spectrum <-55 to -55\n",
        "        data = data/dBlim + 1\n",
        "\n",
        "    elif normalization == 'manual':\n",
        "        m_max = 10369993.175721595 # SC spectral domain\n",
        "        print('max:', m_max)\n",
        "        data = data/m_max\n",
        "\n",
        "    # the number of grid points\n",
        "    i_x = data.shape[1]\n",
        "\n",
        "    # Make the time series\n",
        "    num_evo = train_evo+test_evo\n",
        "    evo_size = steps-window_size\n",
        "    num_samples = np.round(num_evo*evo_size).astype(int)\n",
        "    X_data_series = np.zeros((num_samples, window_size, i_x))\n",
        "    Y_data_series = np.zeros((num_samples, i_x))\n",
        "\n",
        "    for evo in range(num_evo):\n",
        "        for step in range(evo_size):\n",
        "            input_data = np.transpose(data[evo, :, step:step + window_size])\n",
        "            output_data = data[evo, :, step + window_size]\n",
        "            series_idx = evo*evo_size + step\n",
        "            X_data_series[series_idx,:,:] = input_data\n",
        "            Y_data_series[series_idx,:] = output_data\n",
        "\n",
        "    X_train = X_data_series[:num_samples - test_evo*evo_size]\n",
        "    X_test = X_data_series[num_samples - test_evo*evo_size:]\n",
        "    Y_train = Y_data_series[:num_samples - test_evo*evo_size]\n",
        "    Y_test = Y_data_series[num_samples - test_evo*evo_size:]\n",
        "\n",
        "    return i_x, X_train, X_test, Y_train, Y_test\n",
        "\n",
        "\n",
        "def load_data_addP(filename, train_evo, test_evo, steps, window_size,\n",
        "                   added_params, normalization='none'):\n",
        "    \"\"\"\n",
        "    Load data. Add input pulse profile as the first step.\n",
        "    The input for the network is 'window_size' times the input profile.\n",
        "    The 'added_params' is removed from the network output.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    filename : filename as string\n",
        "    train_evo : number of training evolutions as integer\n",
        "    test_evo : number of test evolutions as integer\n",
        "    steps : number of propagation steps as integer\n",
        "    window_size : RNN window size as integer\n",
        "    added_params : number of additional parameters as integer\n",
        "    normalization : none (default), max, maxC, dBmQ, dBmCC, manual ...\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    i_x : number of grid points (spectral/temporal) as integer\n",
        "    X_train : training data input, shape (N, window_size, i_x+added_params)\n",
        "    X_test : testing data input, shape (M, window_size, i_x+added_params)\n",
        "    Y_train : training data output, shape (N, i_x)\n",
        "    Y_test : testing data output, shape (M, i_x)\n",
        "    \"\"\"\n",
        "\n",
        "    # Load data\n",
        "    mat_contents = sio.loadmat(filename)\n",
        "    data = mat_contents['data']\n",
        "    print(\"data loaded...\")\n",
        "    print(data.shape)\n",
        "\n",
        "    if normalization == 'none':\n",
        "        pass\n",
        "\n",
        "    elif normalization == 'max':  # linear scale (normalized)\n",
        "        m_max = np.max(np.fabs(data))\n",
        "        print('max:', m_max)\n",
        "        data = data/m_max\n",
        "\n",
        "    elif normalization == 'maxC': # linear scale with chirp parameter\n",
        "        m_max = np.max(np.fabs(data))\n",
        "        print('max:', m_max)\n",
        "        # normalize data\n",
        "        data[:, added_params:, :] = data[:, added_params:, :]/m_max\n",
        "        # normalize additional parameters (interval [-8,8] for chirp)\n",
        "        data[:, :added_params, :] = (data[:, :added_params, :] + 8)/16\n",
        "\n",
        "    elif normalization == 'dBmQ':  # logarithmic scale with q parameter\n",
        "        m_max = np.max(np.fabs(data))\n",
        "        print('max:', m_max)\n",
        "        # normalize data\n",
        "        data[:, added_params:, :] = data[:, added_params:, :]/m_max\n",
        "        data[:, added_params:, :] = 10*np.log10(data[:, added_params:, :]) # dB scale\n",
        "        dBlim = 55  # define dynamic range\n",
        "        data[data < -dBlim] = -dBlim  # set spectrum <-55 to -55\n",
        "        data[:, added_params:, :] = data[:, added_params:, :]/dBlim + 1\n",
        "        # use interval [1,9] for q parameter\n",
        "        data[:, :added_params, :] = data[:, :added_params, :]/9\n",
        "\n",
        "    elif normalization == 'dBmCC':  # logarithmic scale with coupling conditions\n",
        "        m_max = np.max(np.fabs(data))\n",
        "        print('max:', m_max)\n",
        "        # normalize data, coupling conditions are already normalized ([0, 1])\n",
        "        data[:, added_params:, :] = data[:, added_params:, :]/m_max\n",
        "        data[:, added_params:, :] = 10*np.log10(data[:, added_params:, :]) # dB scale\n",
        "        dBlim = 55  # define dynamic range\n",
        "        data[data < -dBlim] = -dBlim  # set spectrum <-55 to -55\n",
        "        data[:, added_params:, :] = data[:, added_params:, :]/dBlim + 1\n",
        "\n",
        "    elif normalization == 'manual':\n",
        "        m_max = 10369993.175721595 # SC spectral domain\n",
        "        print('max:', m_max)\n",
        "        data = data/m_max\n",
        "\n",
        "\n",
        "    # the number of grid points\n",
        "    i_x = data.shape[1] - added_params\n",
        "\n",
        "    # Make the time series\n",
        "    num_evo = train_evo + test_evo\n",
        "    evo_size = steps - 1\n",
        "    num_samples = np.round(num_evo*evo_size).astype(int)\n",
        "    X_data_series = np.zeros((num_samples, window_size, i_x + added_params))\n",
        "    Y_data_series = np.zeros((num_samples, i_x))\n",
        "\n",
        "    for evo in range(num_evo):\n",
        "        evo_data = np.transpose(data[evo, :, :])\n",
        "\n",
        "        # tile the beginning of the evolution with 'window_size' input profiles\n",
        "        temp1 = evo_data[0, :]\n",
        "        temp2 = np.tile(temp1, (window_size - 1,1))\n",
        "        evo_data = np.vstack((temp2, evo_data))\n",
        "\n",
        "        for step in range(evo_size):\n",
        "            input_data = evo_data[step:step + window_size, :]\n",
        "            # remove additional parameters from output\n",
        "            output_data = evo_data[step + window_size, added_params:]\n",
        "            series_idx = evo*evo_size + step\n",
        "            X_data_series[series_idx, :, :] = input_data\n",
        "            Y_data_series[series_idx, :] = output_data\n",
        "\n",
        "    X_train = X_data_series[:num_samples - test_evo*evo_size]\n",
        "    X_test = X_data_series[num_samples - test_evo*evo_size:]\n",
        "    Y_train = Y_data_series[:num_samples - test_evo*evo_size]\n",
        "    Y_test = Y_data_series[num_samples - test_evo*evo_size:]\n",
        "\n",
        "    return i_x, X_train, X_test, Y_train, Y_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjM3zundwI_7"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2NZaqOZwKQa"
      },
      "outputs": [],
      "source": [
        "#!/urs/bin/env python3\n",
        "\n",
        "\"\"\"\n",
        "Create and update recurrent neural network.\n",
        "\"\"\"\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, LSTM, GRU , Dropout\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import History\n",
        "from keras import optimizers\n",
        "\n",
        "\n",
        "def make_RNN_model(window_size, i_x, added_params=0):\n",
        "    \"\"\"\n",
        "    Create RNN model\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    window_size : RNN window size as integer\n",
        "    i_x : number of grid points as integer\n",
        "    added_params : number of additional parameters as integer (optional)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    model : keras model\n",
        "    \"\"\"\n",
        "    # Define model architecture\n",
        "    model = Sequential()\n",
        "\n",
        "    a = 'relu'\n",
        "    input_shape = (window_size, i_x+added_params)\n",
        "\n",
        "    model.add(GRU(250, activation=a, input_shape=input_shape))\n",
        "    model.add(Dense(250, activation=a))\n",
        "    model.add(Dense(i_x, activation='sigmoid'))\n",
        "\n",
        "    # Compile model\n",
        "    loss = 'mean_squared_error'\n",
        "    model.compile(loss=loss,\n",
        "                  optimizer='adam',\n",
        "                  metrics=['mse', 'mae'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def update_RNN_model(model):\n",
        "    \"\"\"\n",
        "    Update RNN model: learning rate, loss, etc..\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : keras model\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    model : keras model\n",
        "    \"\"\"\n",
        "\n",
        "    # Compile model\n",
        "    #optimizer = optimizers.RMSprop(lr=1e-5)\n",
        "    loss = 'mean_squared_error'\n",
        "    model.compile(loss=loss,\n",
        "                  optimizer='adam',\n",
        "                  metrics=['mse', 'mae'])\n",
        "\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX71QmDLwdnD"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18ohBR4nwXYi"
      },
      "outputs": [],
      "source": [
        "#!/urs/bin/env python3\n",
        "\n",
        "\"\"\"\n",
        "Functions for predicting the evolution for various input intensity profiles.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "\n",
        "def pred_evo(model, X_test, test_evo, steps, window_size, i_x):\n",
        "    \"\"\"\n",
        "    Predict evolution from a given input step. The input is 'window_size' times\n",
        "    the given input.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : Keras model\n",
        "    X_test: : test data, size (samples, window_size, i_x)\n",
        "    test_evo : number of test evolutions as integer\n",
        "    steps : steps as integer\n",
        "    window_size : RNN window size as integer\n",
        "    i_x : number of grid points (spectral/temporal) as integer\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Y_submit : results matrix, size (samples, i_x)\n",
        "    \"\"\"\n",
        "\n",
        "    # Make the time series\n",
        "    evo_size = steps - 1\n",
        "    Y_submit = np.zeros((test_evo, evo_size, i_x))\n",
        "    test_data = X_test[::evo_size,:,:]  # select fiber input profiles\n",
        "\n",
        "    for step in range(evo_size):\n",
        "        test_result = model.predict(test_data)\n",
        "        Y_submit[:,step,:] = test_result\n",
        "        test_result = np.expand_dims(test_result, axis=1)\n",
        "        test_data = np.concatenate((test_data,test_result), axis=1)\n",
        "        test_data = test_data[:, 1:, :]\n",
        "\n",
        "    # reshape to the original dimensions\n",
        "    Y_submit = np.reshape(Y_submit,(evo_size*test_evo, i_x))\n",
        "\n",
        "    return Y_submit\n",
        "\n",
        "\n",
        "def pred_evo_expt(model, X_test, test_evo, steps, window_size, i_x):\n",
        "    \"\"\"\n",
        "    Predict evolution from given 'window_size' number of steps.\n",
        "    To be used with data sets \"HOS_expt_time_151\" and \"HOS_expt_spec_126\".\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : Keras model\n",
        "    X_test: : test data, size (samples, window_size, i_x)\n",
        "    test_evo : number of test evolutions as integer\n",
        "    steps : steps as integer\n",
        "    window_size : RNN window size as integer\n",
        "    i_x : number of grid points (spectral/temporal) as integer\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Y_submit : results matrix, size (samples, i_x)\n",
        "    \"\"\"\n",
        "\n",
        "    # Make the time series\n",
        "    evo_size = steps - window_size\n",
        "    Y_submit = np.zeros((test_evo, evo_size, i_x))\n",
        "    test_data = X_test[::evo_size, :, :]  # select fiber input profiles\n",
        "\n",
        "    for step in range(evo_size):\n",
        "        test_result = model.predict(test_data)\n",
        "        Y_submit[:, step, :] = test_result\n",
        "        test_result = np.expand_dims(test_result, axis=1)\n",
        "        test_data = np.concatenate((test_data,test_result), axis=1)\n",
        "        test_data = test_data[:, 1:, :]\n",
        "\n",
        "    # reshape to the original dimensions\n",
        "    Y_submit = np.reshape(Y_submit,(evo_size*test_evo, i_x))\n",
        "\n",
        "    return Y_submit\n",
        "\n",
        "def pred_evo_addP(model, X_test, test_evo, steps, window_size, added_params, i_x):\n",
        "    \"\"\"\n",
        "    Predict evolution from a given input step. The input is 'window_size' times\n",
        "    the given input. The 'added_params' is passed in the predictions.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : Keras model\n",
        "    X_test: : test data, size (samples, window_size, i_x)\n",
        "    test_evo : number of test evolutions as integer\n",
        "    steps : steps as integer\n",
        "    window_size : RNN window size as integer\n",
        "    added_params : number of additional parameters as integer\n",
        "    i_x : number of grid points (spectral/temporal) as integer\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Y_submit : results matrix, size (samples, i_x)\n",
        "    \"\"\"\n",
        "\n",
        "    # Make the time series\n",
        "    evo_size = steps - 1\n",
        "    Y_submit = np.zeros((test_evo, evo_size, i_x))\n",
        "    test_data = X_test[::evo_size, :, :]  # select fiber input profiles\n",
        "\n",
        "    for step in range(evo_size):\n",
        "        test_result = model.predict(test_data)\n",
        "        Y_submit[:, step, :] = test_result\n",
        "        ap = test_data[:, 0, :added_params]\n",
        "        # pass the additional variables for the prediction\n",
        "        test_result = np.concatenate((ap, test_result), axis=1)\n",
        "        test_result = np.expand_dims(test_result, axis=1)\n",
        "        test_data = np.concatenate((test_data,test_result), axis=1)\n",
        "        test_data = test_data[:, 1:, :]\n",
        "\n",
        "    # reshape to the original dimensions\n",
        "    Y_submit = np.reshape(Y_submit,(evo_size*test_evo, i_x))\n",
        "\n",
        "    return Y_submit\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "044PpRsiOZ3R"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRIJO5FwOa9c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def plot_history(history, timestr, add_time):\n",
        "    plt.figure()\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.plot(history.epoch, np.array(history.history['loss']),\n",
        "           label='Train Loss')\n",
        "    plt.plot(history.epoch, np.array(history.history['val_loss']),\n",
        "           label = 'Val loss')\n",
        "    plt.legend()\n",
        "    #plt.show()\n",
        "    if add_time:\n",
        "        fname = '/content/drive/MyDrive/RNN/exp/plotdata'+timestr+'.png'\n",
        "    else:\n",
        "        fname = '/content/drive/MyDrive/RNN/plotdata.png'\n",
        "    plt.savefig(fname)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ccyr2D8JOcBC"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7iOYmXXweZk"
      },
      "outputs": [],
      "source": [
        "#!/urs/bin/env python3\n",
        "\n",
        "\"\"\"\n",
        "Train RNN model for predicting higher-order soliton and supercontinuum spectral\n",
        "and temporal evolutions. Normalized NLSE, GNLSE and multimode GNLSE have been\n",
        "added.\n",
        "--salmelal--\n",
        "\n",
        "Lauri Salmela\n",
        "lauri.salmela@tuni.fi\n",
        "Tampere University, 2020\n",
        "\"\"\"\n",
        "\n",
        "##########################\n",
        "# mytime = time of indian timezone\n",
        "import datetime\n",
        "now_utc = datetime.datetime.utcnow()\n",
        "IST = datetime.timezone(datetime.timedelta(hours=5, minutes=30))\n",
        "now_ist = now_utc.astimezone(IST)\n",
        "mytime = now_ist.strftime('%H:%M-%Y-%m-%d')\n",
        "#####################\n",
        "\n",
        "switch = 1 # 0 if LSTM & 1 if GRU\n",
        "model_name = \"\"\n",
        "\n",
        "if switch == 0:\n",
        "\tmodel_name = \"LSTM\"\n",
        "else:\n",
        "\tmodel_name = \"GRU\"\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "from matplotlib import pyplot as plt\n",
        "import scipy.io as sio\n",
        "import time\n",
        "import sys\n",
        "\n",
        "# from load_data import *\n",
        "# from make_RNN_model import *\n",
        "# from pred_evo import *\n",
        "# from utils import plot_history\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "\tnp.random.seed(123)  # for reproducibility\n",
        "\n",
        "\tprint(sys.version)\n",
        "\tstart = time.time()\n",
        "\n",
        "\tadd_time = 1  # add time stamp for saved results. Yes (1), No (0)\n",
        "\n",
        "\t### training\n",
        "\tnum_epoch = 60 # 50(original) number of epochs\n",
        "\twindow_size = 10 # RNN window size\n",
        "\n",
        "\t# select data file\n",
        "\t#filename = 'simulations/HOS_NLSE_time_145.mat' # train_evo=2900, test_evo=100, steps=101, i_x=145\n",
        "\t#filename = 'simulations/HOS_NLSE_spec_126.mat' # train_evo=2900, test_evo=100, steps=101, i_x=145\n",
        "\t#filename = 'simulations/HOS_expt_time_151.mat' # train_evo=2899, test_evo=100, steps=110, i_x=151\n",
        "\t#filename = 'simulations/HOS_expt_spec_126.mat' # train_evo=2899, test_evo=100, steps=110, i_x=126\n",
        "\t#filename = 'simulations/SC_time_276.mat' # train_evo=1250, test_evo=50, steps=200, i_x=276\n",
        "\t#filename = 'simulations/SC_spec_251.mat' # train_evo=1250, test_evo=50, steps=200, i_x=251\n",
        "\t#filename = 'simulations/norm_NLSE_time_256.mat' # train_evo=950, test_evo=50, steps=101, i_x=256\n",
        "\t#filename = 'simulations/norm_NLSE_spec_128.mat' # train_evo=950, test_evo=50, steps=101, i_x=128\n",
        "\tfilename = '/content/drive/MyDrive/RNN/data.mat'\n",
        "\t#filename = 'simulations/chirped_NLSE_time_256.mat' # train_evo=5900, test_evo=100, steps=101, i_x=256, added_params=10\n",
        "\t#filename = 'simulations/norm_GNLSE_spec_132.mat' # train_evo=11800, test_evo=200, steps=51, i_x=132, added_params=10\n",
        "\t#filename = 'simulations/MMGNLSE_spec_301.mat' # train_evo=950, test_evo=50, steps=100, i_x=256, added_params=25\n",
        "\n",
        "\n",
        "\t# define samples for training and testing, and the number of propagation\n",
        "\t# steps in the evolution\n",
        "\ttrain_evo, test_evo, steps = 950, 50, 101\n",
        "\n",
        "\t# define the number of added parameters for chirped_NLSE_time_256 (10),\n",
        "\t# norm_GNLSE_spec_132 (10) and MMGNLSE_spec_301 (25). 0 for other cases.\n",
        "\tadded_params = 0\n",
        "\n",
        "\t# load data\n",
        "\ti_x, X_train, X_test, Y_train, Y_test = load_data(filename, train_evo,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t  test_evo, steps,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t  window_size,'dBm') # max/dBm\n",
        "\n",
        "\t# load_data_expt is used with HOS_expt_time_151 and HOS_expt_spec_126\n",
        "\t#i_x, X_train, X_test, Y_train, Y_test = load_data_expt(filename, train_evo,\n",
        "\t#\t\t\t\t\t\t\t\t\t\t\t\t\t   test_evo, steps,\n",
        "\t#\t\t\t\t\t\t\t\t\t\t\t\t\t   window_size,'max') # max/dBm\n",
        "\n",
        "\t# load_data_addP is used with chirped_NLSE_time_256, norm_GNLSE_spec_132\n",
        "\t# and MMGNLSE_spec_301\n",
        "\t#i_x, X_train, X_test, Y_train, Y_test = load_data_addP(filename, train_evo,\n",
        "\t#\t\t\t\t\t\t\t\t\t\t\t\t\t   test_evo, steps,\n",
        "\t#\t\t\t\t\t\t\t\t\t\t\t\t\t   window_size,\n",
        "\t#\t\t\t\t\t\t\t\t\t\t\t\t\t   added_params, 'maxC') # maxC/dBmQ/dBmCC\n",
        "\n",
        "\tprint(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
        "\tprint(\"READY...\")\n",
        "\n",
        "\t# create new model (0) or load ready model (1)\n",
        "\tmodel_ready = 0\n",
        "\n",
        "\tif model_ready == 0:\n",
        "\t\t# Define model architecture\n",
        "\t\tmodel = make_RNN_model(window_size, i_x)\n",
        "\n",
        "\t\t# with additional parameters\n",
        "\t\t#model = make_RNN_model(window_size, i_x, added_params)\n",
        "\n",
        "\telif model_ready == 1:\n",
        "\t\t# Load saved model\n",
        "\t\tmodel = load_model('nets/evo.h5')\n",
        "\n",
        "\t\tmodel = update_RNN_model(model)\n",
        "\n",
        "\tmodel.summary()\n",
        "\n",
        "\t### Fit model on training data\n",
        "\thistory = model.fit(X_train, Y_train,\n",
        "\t\t\t\t\t\tepochs=num_epoch,\n",
        "\t\t\t\t\t\tvalidation_split=0.1,\n",
        "\t\t\t\t\t\tverbose=2)\n",
        "\n",
        "\tend = time.time()\n",
        "\tprint(\"Elapsed time: %d seconds.\" % (end-start))\n",
        "\n",
        "\ttimestr = time.strftime(\"%Y%m%d-%H:%M\")\n",
        "\n",
        "\tplot_history(history, timestr, add_time)\n",
        "\n",
        " \t# Save net\n",
        "\tif add_time:\n",
        "\t\tfname = '/content/drive/MyDrive/RNN/exp/netsEvo_'+model_name+mytime+'.h5'\n",
        "\telse:\n",
        "\t\tfname = '/content/drive/MyDrive/RNN/exp/netsEvo.h5'\n",
        "\tmodel.save(fname)\n",
        "\n",
        "\tprint(\"TESTING STEP-WISE...\")\n",
        "\tY_submit = model.predict(X_test)\n",
        "\n",
        "\tprint('saving results...')\n",
        "\tif add_time:\n",
        "\t\tfname = '/content/drive/MyDrive/RNN/exp/test_results'+model_name+mytime+'.mat'\n",
        "\telse:\n",
        "\t\tfname = '/content/drive/MyDrive/RNN/exp/test_results.mat'\n",
        "\tsio.savemat(fname, {'Y_submit':Y_submit, 'Y_test':Y_test, 'steps':steps,\n",
        "\t\t\t\t\t\t'window_size':window_size})\n",
        "\n",
        "\tprint(\"TESTING USING INPUT PROFILE ONLY...\")\n",
        "\n",
        "\tY_submit = pred_evo(model, X_test, test_evo, steps, window_size, i_x)\n",
        "\n",
        "\t# pred_evo_expt is used with HOS_expt_time_151 and HOS_expt_spec_126\n",
        "\t#Y_submit = pred_evo_expt(model, X_test, test_evo, steps, window_size, i_x)\n",
        "\n",
        "\t# pred_evo_expt is used with chirped_NLSE_time_256, norm_GNLSE_spec_132\n",
        "\t# and MMGNLSE_spec_301\n",
        "\t#Y_submit = pred_evo_addP(model, X_test, test_evo, steps, window_size,\n",
        "\t#\t\t\t\t\t\t added_params, i_x)\n",
        "\n",
        "\tprint('saving results from start...')\n",
        "\tif add_time:\n",
        "\t\tfname = '/content/drive/MyDrive/RNN/exp/full_test_results_'+model_name+mytime+'.mat'\n",
        "\telse:\n",
        "\t\tfname = '/content/drive/MyDrive/RNN/exp/full_test_results.mat'\n",
        "\tsio.savemat(fname, {'Y_submit':Y_submit, 'Y_test':Y_test, 'steps':steps,\n",
        "\t\t\t\t\t\t'window_size':window_size})\n",
        "\tprint('all done ' , mytime)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgQ06sScwRDS"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}