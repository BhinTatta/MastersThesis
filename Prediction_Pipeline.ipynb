{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F45PApp4vkLQ"
      },
      "outputs": [],
      "source": [
        "#!/urs/bin/env python3\n",
        "\n",
        "\"\"\"\n",
        "Codes for loading and preprocessing the data.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "\n",
        "\n",
        "def load_data(filename, train_evo, test_evo, steps, window_size,\n",
        "              normalization='none'):\n",
        "    \"\"\"\n",
        "    Load data. Add input pulse profile as the first step.\n",
        "    The input for the network is 'window_size' times the input profile.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    filename : filename as string\n",
        "    train_evo : number of training evolutions as integer\n",
        "    test_evo : number of test evolutions as integer\n",
        "    steps : number of propagation steps as integer\n",
        "    window_size : RNN window size as integer\n",
        "    normalization : none (default), max, dBm, manual ...\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    i_x : number of grid points (spectral/temporal) as integer\n",
        "    X_train : training data input, shape (N, window_size, i_x)\n",
        "    X_test : testing data input, shape (M, window_size, i_x)\n",
        "    Y_train : training data output, shape (N, i_x)\n",
        "    Y_test : testing data output, shape (M, i_x)\n",
        "    \"\"\"\n",
        "\n",
        "    # Load data\n",
        "    mat_contents = sio.loadmat(filename)\n",
        "    data = mat_contents['data']\n",
        "    print(\"data loaded...\")\n",
        "    print(data.shape)\n",
        "\n",
        "    if normalization == 'none':\n",
        "        pass\n",
        "        \n",
        "    elif normalization == 'max':  # linear scale (normalized)\n",
        "        m_max = np.max(np.fabs(data))\n",
        "        print('max:', m_max)\n",
        "        data = data/m_max\n",
        "\n",
        "    elif normalization == 'dBm':  # logarithmic scale\n",
        "        m_max = np.max(np.fabs(data))\n",
        "        print('max:', m_max)\n",
        "        data=data/m_max  # normalize\n",
        "        data = 10*np.log10(data)  # dB scale\n",
        "        dBlim = 55  # define dynamic range\n",
        "        data[data < -dBlim] = -dBlim  # set spectrum <-55 to -55\n",
        "        data = data/dBlim + 1\n",
        "\n",
        "    elif normalization == 'manual':\n",
        "        m_max = 10369993.175721595 # SC spectral domain\n",
        "        print('max:', m_max)\n",
        "        data = data/m_max\n",
        "\n",
        "\n",
        "    # the number of grid points\n",
        "    i_x = data.shape[1]\n",
        "\n",
        "    # Make the time series\n",
        "    num_evo = train_evo + test_evo\n",
        "    evo_size = steps - 1\n",
        "    num_samples = np.round(num_evo*evo_size).astype(int)\n",
        "    X_data_series = np.zeros((num_samples, window_size, i_x))\n",
        "    Y_data_series = np.zeros((num_samples, i_x))\n",
        "\n",
        "    for evo in range(num_evo):\n",
        "        evo_data = np.transpose(data[evo, :, :])\n",
        "\n",
        "        # tile the beginning of the evolution with 'window_size' input profiles\n",
        "        temp1 = evo_data[0, :]\n",
        "        temp2 = np.tile(temp1, (window_size - 1, 1))\n",
        "        evo_data = np.vstack((temp2, evo_data))\n",
        "\n",
        "        for step in range(evo_size):\n",
        "            input_data = evo_data[step:step + window_size, :]\n",
        "            output_data = evo_data[step + window_size, :]\n",
        "            series_idx = evo*evo_size + step\n",
        "            X_data_series[series_idx, :, :] = input_data\n",
        "            Y_data_series[series_idx, :] = output_data\n",
        "\n",
        "\n",
        "    X_train = X_data_series[:num_samples - test_evo*evo_size]\n",
        "    X_test = X_data_series[num_samples - test_evo*evo_size:]\n",
        "    Y_train = Y_data_series[:num_samples - test_evo*evo_size]\n",
        "    Y_test = Y_data_series[num_samples - test_evo*evo_size:]\n",
        "\n",
        "    return i_x, X_train, X_test, Y_train, Y_test\n",
        "\n",
        "\n",
        "def load_data_expt(filename, train_evo, test_evo, steps, window_size,\n",
        "                   normalization='none'):\n",
        "    \"\"\"\n",
        "    Load data to predict the evolution from a given 'window_size' steps.\n",
        "    To be used with data sets \"HOS_expt_time_151\" and \"HOS_expt_spec_126\".\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    filename : filename as string\n",
        "    train_evo : number of training evolutions as integer\n",
        "    test_evo : number of test evolutions as integer\n",
        "    steps : number of propagation steps as integer\n",
        "    window_size : RNN window size as integer\n",
        "    normalization : none (default), max, manual ...\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    i_x : number of grid points (spectral/temporal) as integer\n",
        "    X_train : training data input, shape (N, window_size, i_x)\n",
        "    X_test : testing data input, shape (M, window_size, i_x)\n",
        "    Y_train : training data output, shape (N, i_x)\n",
        "    Y_test : testing data output, shape (M, i_x)\n",
        "    \"\"\"\n",
        "\n",
        "    # Load data\n",
        "    mat_contents = sio.loadmat(filename)\n",
        "    data = mat_contents['data']\n",
        "    print(\"data loaded...\")\n",
        "    print(data.shape)\n",
        "\n",
        "    if normalization == 'none':\n",
        "        pass\n",
        "\n",
        "    elif normalization == 'max':  # linear scale (normalized)\n",
        "        m_max = np.max(np.fabs(data))\n",
        "        print('max:', m_max)\n",
        "        data = data/m_max\n",
        "\n",
        "    elif normalization == 'dBm':  # logarithmic scale\n",
        "        m_max = np.max(np.fabs(data))\n",
        "        print('max:', m_max)\n",
        "        data=data/m_max  # normalize\n",
        "        data = 10*np.log10(data)  # dB scale\n",
        "        dBlim = 55  # define dynamic range\n",
        "        data[data < -dBlim] = -dBlim  # set spectrum <-55 to -55\n",
        "        data = data/dBlim + 1\n",
        "\n",
        "    elif normalization == 'manual':\n",
        "        m_max = 10369993.175721595 # SC spectral domain\n",
        "        print('max:', m_max)\n",
        "        data = data/m_max\n",
        "\n",
        "    # the number of grid points\n",
        "    i_x = data.shape[1]\n",
        "\n",
        "    # Make the time series\n",
        "    num_evo = train_evo+test_evo\n",
        "    evo_size = steps-window_size\n",
        "    num_samples = np.round(num_evo*evo_size).astype(int)\n",
        "    X_data_series = np.zeros((num_samples, window_size, i_x))\n",
        "    Y_data_series = np.zeros((num_samples, i_x))\n",
        "\n",
        "    for evo in range(num_evo):\n",
        "        for step in range(evo_size):\n",
        "            input_data = np.transpose(data[evo, :, step:step + window_size])\n",
        "            output_data = data[evo, :, step + window_size]\n",
        "            series_idx = evo*evo_size + step\n",
        "            X_data_series[series_idx,:,:] = input_data\n",
        "            Y_data_series[series_idx,:] = output_data\n",
        "\n",
        "    X_train = X_data_series[:num_samples - test_evo*evo_size]\n",
        "    X_test = X_data_series[num_samples - test_evo*evo_size:]\n",
        "    Y_train = Y_data_series[:num_samples - test_evo*evo_size]\n",
        "    Y_test = Y_data_series[num_samples - test_evo*evo_size:]\n",
        "\n",
        "    return i_x, X_train, X_test, Y_train, Y_test\n",
        "\n",
        "\n",
        "def load_data_addP(filename, train_evo, test_evo, steps, window_size,\n",
        "                   added_params, normalization='none'):\n",
        "    \"\"\"\n",
        "    Load data. Add input pulse profile as the first step.\n",
        "    The input for the network is 'window_size' times the input profile.\n",
        "    The 'added_params' is removed from the network output.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    filename : filename as string\n",
        "    train_evo : number of training evolutions as integer\n",
        "    test_evo : number of test evolutions as integer\n",
        "    steps : number of propagation steps as integer\n",
        "    window_size : RNN window size as integer\n",
        "    added_params : number of additional parameters as integer\n",
        "    normalization : none (default), max, maxC, dBmQ, dBmCC, manual ...\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    i_x : number of grid points (spectral/temporal) as integer\n",
        "    X_train : training data input, shape (N, window_size, i_x+added_params)\n",
        "    X_test : testing data input, shape (M, window_size, i_x+added_params)\n",
        "    Y_train : training data output, shape (N, i_x)\n",
        "    Y_test : testing data output, shape (M, i_x)\n",
        "    \"\"\"\n",
        "\n",
        "    # Load data\n",
        "    mat_contents = sio.loadmat(filename)\n",
        "    data = mat_contents['data']\n",
        "    print(\"data loaded...\")\n",
        "    print(data.shape)\n",
        "\n",
        "    if normalization == 'none':\n",
        "        pass\n",
        "\n",
        "    elif normalization == 'max':  # linear scale (normalized)\n",
        "        m_max = np.max(np.fabs(data))\n",
        "        print('max:', m_max)\n",
        "        data = data/m_max\n",
        "\n",
        "    elif normalization == 'maxC': # linear scale with chirp parameter\n",
        "        m_max = np.max(np.fabs(data))\n",
        "        print('max:', m_max)\n",
        "        # normalize data\n",
        "        data[:, added_params:, :] = data[:, added_params:, :]/m_max\n",
        "        # normalize additional parameters (interval [-8,8] for chirp)\n",
        "        data[:, :added_params, :] = (data[:, :added_params, :] + 8)/16\n",
        "\n",
        "    elif normalization == 'dBmQ':  # logarithmic scale with q parameter\n",
        "        m_max = np.max(np.fabs(data))\n",
        "        print('max:', m_max)\n",
        "        # normalize data\n",
        "        data[:, added_params:, :] = data[:, added_params:, :]/m_max\n",
        "        data[:, added_params:, :] = 10*np.log10(data[:, added_params:, :]) # dB scale\n",
        "        dBlim = 55  # define dynamic range\n",
        "        data[data < -dBlim] = -dBlim  # set spectrum <-55 to -55\n",
        "        data[:, added_params:, :] = data[:, added_params:, :]/dBlim + 1\n",
        "        # use interval [1,9] for q parameter\n",
        "        data[:, :added_params, :] = data[:, :added_params, :]/9\n",
        "\n",
        "    elif normalization == 'dBmCC':  # logarithmic scale with coupling conditions\n",
        "        m_max = np.max(np.fabs(data))\n",
        "        print('max:', m_max)\n",
        "        # normalize data, coupling conditions are already normalized ([0, 1])\n",
        "        data[:, added_params:, :] = data[:, added_params:, :]/m_max\n",
        "        data[:, added_params:, :] = 10*np.log10(data[:, added_params:, :]) # dB scale\n",
        "        dBlim = 55  # define dynamic range\n",
        "        data[data < -dBlim] = -dBlim  # set spectrum <-55 to -55\n",
        "        data[:, added_params:, :] = data[:, added_params:, :]/dBlim + 1\n",
        "\n",
        "    elif normalization == 'manual':\n",
        "        m_max = 10369993.175721595 # SC spectral domain\n",
        "        print('max:', m_max)\n",
        "        data = data/m_max\n",
        "\n",
        "\n",
        "    # the number of grid points\n",
        "    i_x = data.shape[1] - added_params\n",
        "\n",
        "    # Make the time series\n",
        "    num_evo = train_evo + test_evo\n",
        "    evo_size = steps - 1\n",
        "    num_samples = np.round(num_evo*evo_size).astype(int)\n",
        "    X_data_series = np.zeros((num_samples, window_size, i_x + added_params))\n",
        "    Y_data_series = np.zeros((num_samples, i_x))\n",
        "\n",
        "    for evo in range(num_evo):\n",
        "        evo_data = np.transpose(data[evo, :, :])\n",
        "\n",
        "        # tile the beginning of the evolution with 'window_size' input profiles\n",
        "        temp1 = evo_data[0, :]\n",
        "        temp2 = np.tile(temp1, (window_size - 1,1))\n",
        "        evo_data = np.vstack((temp2, evo_data))\n",
        "\n",
        "        for step in range(evo_size):\n",
        "            input_data = evo_data[step:step + window_size, :]\n",
        "            # remove additional parameters from output\n",
        "            output_data = evo_data[step + window_size, added_params:]\n",
        "            series_idx = evo*evo_size + step\n",
        "            X_data_series[series_idx, :, :] = input_data\n",
        "            Y_data_series[series_idx, :] = output_data\n",
        "\n",
        "    X_train = X_data_series[:num_samples - test_evo*evo_size]\n",
        "    X_test = X_data_series[num_samples - test_evo*evo_size:]\n",
        "    Y_train = Y_data_series[:num_samples - test_evo*evo_size]\n",
        "    Y_test = Y_data_series[num_samples - test_evo*evo_size:]\n",
        "\n",
        "    return i_x, X_train, X_test, Y_train, Y_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjM3zundwI_7"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2NZaqOZwKQa"
      },
      "outputs": [],
      "source": [
        "#!/urs/bin/env python3\n",
        "\n",
        "\"\"\"\n",
        "Create and update recurrent neural network.\n",
        "\"\"\"\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, LSTM, GRU\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import History\n",
        "from keras import optimizers\n",
        "\n",
        "\n",
        "from keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "# def make_RNN_model(window_size, i_x, added_params=0):\n",
        "#     \"\"\"\n",
        "#     Create RNN model\n",
        "\n",
        "#     Parameters\n",
        "#     ----------\n",
        "#     window_size : RNN window size as integer\n",
        "#     i_x : number of grid points as integer\n",
        "#     added_params : number of additional parameters as integer (optional)\n",
        "\n",
        "#     Returns\n",
        "#     -------\n",
        "#     model : keras model\n",
        "#     \"\"\"\n",
        "\n",
        "#     # Define model architecture\n",
        "#     model = Sequential()\n",
        "\n",
        "#     a = 'relu'\n",
        "#     input_shape = (window_size, i_x+added_params)\n",
        "\n",
        "#     # Add 2 GRU layers with dropout\n",
        "#     model.add(GRU(250, activation=a, input_shape=input_shape, return_sequences=True))\n",
        "#     model.add(GRU(250, activation=a))\n",
        "#     model.add(Dropout(0.2))\n",
        "\n",
        "#     # Add dense layers\n",
        "#     model.add(Dense(250, activation=a))\n",
        "#     model.add(Dense(250, activation=a))\n",
        "#     model.add(Dense(250, activation=a))\n",
        "#     # Output layer\n",
        "#     model.add(Dense(i_x, activation='sigmoid'))\n",
        "\n",
        "#     # Compile model\n",
        "#     optimizer = optimizers.Adam(lr=1e-4)\n",
        "#     loss = 'mean_squared_error'\n",
        "#     model.compile(loss=loss,\n",
        "#                   optimizer=optimizer,\n",
        "#                   metrics=['mse', 'mae'])\n",
        "\n",
        "#     return model\n",
        "\n",
        "def make_RNN_model(window_size, i_x, added_params=0):\n",
        "    \"\"\"\n",
        "    Create RNN model\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    window_size : RNN window size as integer\n",
        "    i_x : number of grid points as integer\n",
        "    added_params : number of additional parameters as integer (optional)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    model : keras model\n",
        "    \"\"\"\n",
        "\n",
        "    # Define model architecture\n",
        "    model = Sequential()\n",
        "\n",
        "    a = 'relu'\n",
        "    input_shape = (window_size, i_x+added_params)\n",
        "\n",
        "    model.add(Bidirectional(LSTM(250, activation=a), input_shape=input_shape))\n",
        "    model.add(Dense(250, activation=a))\n",
        "    model.add(Dense(250, activation=a))\n",
        "    model.add(Dense(i_x, activation='sigmoid'))\n",
        "\n",
        "    # Compile model\n",
        "    optimizer = optimizers.RMSprop(lr=1e-4, rho=0.9)\n",
        "    loss = 'mean_squared_error'\n",
        "    model.compile(loss=loss,\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['mse', 'mae'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def update_RNN_model(model):\n",
        "    \"\"\"\n",
        "    Update RNN model: learning rate, loss, etc..\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : keras model\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    model : keras model\n",
        "    \"\"\"\n",
        "\n",
        "    # Compile model\n",
        "    optimizer = optimizers.RMSprop(lr=1e-5)\n",
        "    loss = 'mean_squared_error'\n",
        "    model.compile(loss=loss,\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['mse', 'mae'])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX71QmDLwdnD"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18ohBR4nwXYi"
      },
      "outputs": [],
      "source": [
        "#!/urs/bin/env python3\n",
        "\n",
        "\"\"\"\n",
        "Functions for predicting the evolution for various input intensity profiles.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "\n",
        "def pred_evo(model, X_test, test_evo, steps, window_size, i_x):\n",
        "    \"\"\"\n",
        "    Predict evolution from a given input step. The input is 'window_size' times\n",
        "    the given input.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : Keras model\n",
        "    X_test: : test data, size (samples, window_size, i_x)\n",
        "    test_evo : number of test evolutions as integer\n",
        "    steps : steps as integer\n",
        "    window_size : RNN window size as integer\n",
        "    i_x : number of grid points (spectral/temporal) as integer\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Y_submit : results matrix, size (samples, i_x)\n",
        "    \"\"\"\n",
        "\n",
        "    # Make the time series\n",
        "    evo_size = steps - 1\n",
        "    Y_submit = np.zeros((test_evo, evo_size, i_x))\n",
        "    test_data = X_test[::evo_size,:,:]  # select fiber input profiles\n",
        "\n",
        "    for step in range(evo_size):\n",
        "        test_result = model.predict(test_data)\n",
        "        Y_submit[:,step,:] = test_result\n",
        "        test_result = np.expand_dims(test_result, axis=1)\n",
        "        test_data = np.concatenate((test_data,test_result), axis=1)\n",
        "        test_data = test_data[:, 1:, :]\n",
        "\n",
        "    # reshape to the original dimensions\n",
        "    Y_submit = np.reshape(Y_submit,(evo_size*test_evo, i_x))\n",
        "\n",
        "    return Y_submit\n",
        "\n",
        "\n",
        "def pred_evo_expt(model, X_test, test_evo, steps, window_size, i_x):\n",
        "    \"\"\"\n",
        "    Predict evolution from given 'window_size' number of steps.\n",
        "    To be used with data sets \"HOS_expt_time_151\" and \"HOS_expt_spec_126\".\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : Keras model\n",
        "    X_test: : test data, size (samples, window_size, i_x)\n",
        "    test_evo : number of test evolutions as integer\n",
        "    steps : steps as integer\n",
        "    window_size : RNN window size as integer\n",
        "    i_x : number of grid points (spectral/temporal) as integer\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Y_submit : results matrix, size (samples, i_x)\n",
        "    \"\"\"\n",
        "\n",
        "    # Make the time series\n",
        "    evo_size = steps - window_size\n",
        "    Y_submit = np.zeros((test_evo, evo_size, i_x))\n",
        "    test_data = X_test[::evo_size, :, :]  # select fiber input profiles\n",
        "\n",
        "    for step in range(evo_size):\n",
        "        test_result = model.predict(test_data)\n",
        "        Y_submit[:, step, :] = test_result\n",
        "        test_result = np.expand_dims(test_result, axis=1)\n",
        "        test_data = np.concatenate((test_data,test_result), axis=1)\n",
        "        test_data = test_data[:, 1:, :]\n",
        "\n",
        "    # reshape to the original dimensions\n",
        "    Y_submit = np.reshape(Y_submit,(evo_size*test_evo, i_x))\n",
        "\n",
        "    return Y_submit\n",
        "\n",
        "def pred_evo_addP(model, X_test, test_evo, steps, window_size, added_params, i_x):\n",
        "    \"\"\"\n",
        "    Predict evolution from a given input step. The input is 'window_size' times\n",
        "    the given input. The 'added_params' is passed in the predictions.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : Keras model\n",
        "    X_test: : test data, size (samples, window_size, i_x)\n",
        "    test_evo : number of test evolutions as integer\n",
        "    steps : steps as integer\n",
        "    window_size : RNN window size as integer\n",
        "    added_params : number of additional parameters as integer\n",
        "    i_x : number of grid points (spectral/temporal) as integer\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Y_submit : results matrix, size (samples, i_x)\n",
        "    \"\"\"\n",
        "\n",
        "    # Make the time series\n",
        "    evo_size = steps - 1\n",
        "    Y_submit = np.zeros((test_evo, evo_size, i_x))\n",
        "    test_data = X_test[::evo_size, :, :]  # select fiber input profiles\n",
        "\n",
        "    for step in range(evo_size):\n",
        "        test_result = model.predict(test_data)\n",
        "        Y_submit[:, step, :] = test_result\n",
        "        ap = test_data[:, 0, :added_params]\n",
        "        # pass the additional variables for the prediction\n",
        "        test_result = np.concatenate((ap, test_result), axis=1)\n",
        "        test_result = np.expand_dims(test_result, axis=1)\n",
        "        test_data = np.concatenate((test_data,test_result), axis=1)\n",
        "        test_data = test_data[:, 1:, :]\n",
        "\n",
        "    # reshape to the original dimensions\n",
        "    Y_submit = np.reshape(Y_submit,(evo_size*test_evo, i_x))\n",
        "\n",
        "    return Y_submit\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "044PpRsiOZ3R"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRIJO5FwOa9c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def plot_history(history, timestr, add_time):\n",
        "    plt.figure()\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.plot(history.epoch, np.array(history.history['loss']),\n",
        "           label='Train Loss')\n",
        "    plt.plot(history.epoch, np.array(history.history['val_loss']),\n",
        "           label = 'Val loss')\n",
        "    plt.legend()\n",
        "    #plt.show()\n",
        "    if add_time:\n",
        "        fname = '/content/drive/MyDrive/RNN/exp/plotdata'+timestr+'.png'\n",
        "    else:\n",
        "        fname = '/content/drive/MyDrive/RNN/plotdata.png'\n",
        "    plt.savefig(fname)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ccyr2D8JOcBC"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7iOYmXXweZk"
      },
      "outputs": [],
      "source": [
        "# #!/urs/bin/env python3\n",
        "\n",
        "# \"\"\"\n",
        "# Train RNN model for predicting higher-order soliton and supercontinuum spectral\n",
        "# and temporal evolutions. Normalized NLSE, GNLSE and multimode GNLSE have been\n",
        "# added.\n",
        "# --salmelal--\n",
        "\n",
        "# Lauri Salmela\n",
        "# lauri.salmela@tuni.fi\n",
        "# Tampere University, 2020\n",
        "# \"\"\"\n",
        "\n",
        "# switch = 1 # 0 if LSTM & 1 if GRU\n",
        "# model_name = \"\"\n",
        "\n",
        "# if switch == 0:\n",
        "# \tmodel_name = \"LSTM\"\n",
        "# else:\n",
        "# \tmodel_name = \"GRU\"\n",
        "\n",
        "# import numpy as np\n",
        "# from keras.models import load_model\n",
        "# import matplotlib\n",
        "# matplotlib.use('Agg')\n",
        "# from matplotlib import pyplot as plt\n",
        "# import scipy.io as sio\n",
        "# import time\n",
        "# import sys\n",
        "\n",
        "# # from load_data import *\n",
        "# # from make_RNN_model import *\n",
        "# # from pred_evo import *\n",
        "# # from utils import plot_history\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "\n",
        "# \tnp.random.seed(123)  # for reproducibility\n",
        "\n",
        "# \tprint(sys.version)\n",
        "# \tstart = time.time()\n",
        "\n",
        "# \tadd_time = 1  # add time stamp for saved results. Yes (1), No (0)\n",
        "\n",
        "# \t### training\n",
        "# \tnum_epoch = 50 # 50(original) number of epochs\n",
        "# \twindow_size = 10 # RNN window size\n",
        "\n",
        "# \t# select data file\n",
        "# \t#filename = 'simulations/HOS_NLSE_time_145.mat' # train_evo=2900, test_evo=100, steps=101, i_x=145\n",
        "# \t#filename = 'simulations/HOS_NLSE_spec_126.mat' # train_evo=2900, test_evo=100, steps=101, i_x=145\n",
        "# \t#filename = 'simulations/HOS_expt_time_151.mat' # train_evo=2899, test_evo=100, steps=110, i_x=151\n",
        "# \t#filename = 'simulations/HOS_expt_spec_126.mat' # train_evo=2899, test_evo=100, steps=110, i_x=126\n",
        "# \t#filename = 'simulations/SC_time_276.mat' # train_evo=1250, test_evo=50, steps=200, i_x=276\n",
        "# \t#filename = 'simulations/SC_spec_251.mat' # train_evo=1250, test_evo=50, steps=200, i_x=251\n",
        "# \t#filename = 'simulations/norm_NLSE_time_256.mat' # train_evo=950, test_evo=50, steps=101, i_x=256\n",
        "# \t#filename = 'simulations/norm_NLSE_spec_128.mat' # train_evo=950, test_evo=50, steps=101, i_x=128\n",
        "# \tfilename = '/content/drive/MyDrive/RNN/data.mat'\n",
        "# \t#filename = 'simulations/chirped_NLSE_time_256.mat' # train_evo=5900, test_evo=100, steps=101, i_x=256, added_params=10\n",
        "# \t#filename = 'simulations/norm_GNLSE_spec_132.mat' # train_evo=11800, test_evo=200, steps=51, i_x=132, added_params=10\n",
        "# \t#filename = 'simulations/MMGNLSE_spec_301.mat' # train_evo=950, test_evo=50, steps=100, i_x=256, added_params=25\n",
        "\n",
        "\n",
        "# \t# define samples for training and testing, and the number of propagation\n",
        "# \t# steps in the evolution\n",
        "# \ttrain_evo, test_evo, steps = 950, 50, 101\n",
        "\n",
        "# \t# define the number of added parameters for chirped_NLSE_time_256 (10),\n",
        "# \t# norm_GNLSE_spec_132 (10) and MMGNLSE_spec_301 (25). 0 for other cases.\n",
        "# \tadded_params = 0\n",
        "\n",
        "# \t# load data\n",
        "# \ti_x, X_train, X_test, Y_train, Y_test = load_data(filename, train_evo,\n",
        "# \t\t\t\t\t\t\t\t\t\t\t\t\t  test_evo, steps,\n",
        "# \t\t\t\t\t\t\t\t\t\t\t\t\t  window_size,'dBm') # max/dBm\n",
        "\n",
        "# \t# load_data_expt is used with HOS_expt_time_151 and HOS_expt_spec_126\n",
        "# \t#i_x, X_train, X_test, Y_train, Y_test = load_data_expt(filename, train_evo,\n",
        "# \t#\t\t\t\t\t\t\t\t\t\t\t\t\t   test_evo, steps,\n",
        "# \t#\t\t\t\t\t\t\t\t\t\t\t\t\t   window_size,'max') # max/dBm\n",
        "\n",
        "# \t# load_data_addP is used with chirped_NLSE_time_256, norm_GNLSE_spec_132\n",
        "# \t# and MMGNLSE_spec_301\n",
        "# \t#i_x, X_train, X_test, Y_train, Y_test = load_data_addP(filename, train_evo,\n",
        "# \t#\t\t\t\t\t\t\t\t\t\t\t\t\t   test_evo, steps,\n",
        "# \t#\t\t\t\t\t\t\t\t\t\t\t\t\t   window_size,\n",
        "# \t#\t\t\t\t\t\t\t\t\t\t\t\t\t   added_params, 'maxC') # maxC/dBmQ/dBmCC\n",
        "\n",
        "# \tprint(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
        "# \tprint(\"READY...\")\n",
        "\n",
        "# \t# create new model (0) or load ready model (1)\n",
        "# \tmodel_ready = 0\n",
        "\n",
        "# \tif model_ready == 0:\n",
        "# \t\t# Define model architecture\n",
        "# \t\tmodel = make_RNN_model(window_size, i_x)\n",
        "\n",
        "# \t\t# with additional parameters\n",
        "# \t\t#model = make_RNN_model(window_size, i_x, added_params)\n",
        "\n",
        "# \telif model_ready == 1:\n",
        "# \t\t# Load saved model\n",
        "# \t\tmodel = load_model('nets/evo.h5')\n",
        "\n",
        "# \t\tmodel = update_RNN_model(model)\n",
        "\n",
        "# \tmodel.summary()\n",
        "\n",
        "# \t### Fit model on training data\n",
        "# \thistory = model.fit(X_train, Y_train,\n",
        "# \t\t\t\t\t\tepochs=num_epoch,\n",
        "# \t\t\t\t\t\tvalidation_split=0.1,\n",
        "# \t\t\t\t\t\tverbose=2)\n",
        "\n",
        "# \tend = time.time()\n",
        "# \tprint(\"Elapsed time: %d seconds.\" % (end-start))\n",
        "\n",
        "# \ttimestr = time.strftime(\"%Y%m%d-%H:%M\")\n",
        "\n",
        "# \tplot_history(history, timestr, add_time)\n",
        "\n",
        "#  \t# Save net\n",
        "# \tif add_time:\n",
        "# \t\tfname = '/content/drive/MyDrive/RNN/exp/netsEvo_'+model_name+timestr+'.h5'\n",
        "# \telse:\n",
        "# \t\tfname = '/content/drive/MyDrive/RNN/exp/netsEvo.h5'\n",
        "# \tmodel.save(fname)\n",
        "\n",
        "# \tprint(\"TESTING STEP-WISE...\")\n",
        "# \tY_submit = model.predict(X_test)\n",
        "\n",
        "# \tprint('saving results...')\n",
        "# \tif add_time:\n",
        "# \t\tfname = '/content/drive/MyDrive/RNN/exp/test_results'+model_name+timestr+'.mat'\n",
        "# \telse:\n",
        "# \t\tfname = '/content/drive/MyDrive/RNN/exp/test_results.mat'\n",
        "# \tsio.savemat(fname, {'Y_submit':Y_submit, 'Y_test':Y_test, 'steps':steps,\n",
        "# \t\t\t\t\t\t'window_size':window_size})\n",
        "\n",
        "# \tprint(\"TESTING USING INPUT PROFILE ONLY...\")\n",
        "\n",
        "# \tY_submit = pred_evo(model, X_test, test_evo, steps, window_size, i_x)\n",
        "\n",
        "# \t# pred_evo_expt is used with HOS_expt_time_151 and HOS_expt_spec_126\n",
        "# \t#Y_submit = pred_evo_expt(model, X_test, test_evo, steps, window_size, i_x)\n",
        "\n",
        "# \t# pred_evo_expt is used with chirped_NLSE_time_256, norm_GNLSE_spec_132\n",
        "# \t# and MMGNLSE_spec_301\n",
        "# \t#Y_submit = pred_evo_addP(model, X_test, test_evo, steps, window_size,\n",
        "# \t#\t\t\t\t\t\t added_params, i_x)\n",
        "\n",
        "# \tprint('saving results from start...')\n",
        "# \tif add_time:\n",
        "# \t\tfname = '/content/drive/MyDrive/RNN/exp/full_test_results_'+model_name+timestr+'.mat'\n",
        "# \telse:\n",
        "# \t\tfname = '/content/drive/MyDrive/RNN/exp/full_test_results.mat'\n",
        "# \tsio.savemat(fname, {'Y_submit':Y_submit, 'Y_test':Y_test, 'steps':steps,\n",
        "# \t\t\t\t\t\t'window_size':window_size})\n",
        "# \tprint('all done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgQ06sScwRDS"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just paste the model net location and it tests the model on data along with saving full results in .mat file."
      ],
      "metadata": {
        "id": "CcBxHnZ9isOU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2m8n9vpQwSCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "607b67f5-a547-423b-bc25-84fdfc65b73e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.9.16 (main, Dec  7 2022, 01:11:51) \n",
            "[GCC 9.4.0]\n",
            "data loaded...\n",
            "(1000, 128, 101)\n",
            "max: 1241553.7064835906\n",
            "(95000, 10, 128) (5000, 10, 128) (95000, 128) (5000, 128)\n",
            "READY...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru (GRU)                   (None, 250)               285000    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 250)               62750     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32128     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 379,878\n",
            "Trainable params: 379,878\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TESTING STEP-WISE...\n",
            "157/157 [==============================] - 2s 11ms/step\n",
            "saving results...\n",
            "TESTING USING INPUT PROFILE ONLY...\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 16ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "Elapsed time: 11.009809 seconds.\n",
            "saving results from start...\n",
            "/content/drive/MyDrive/RNN/exp/predictions/GRUadam+2dense-_results_17:29-2023-04-26.mat  all done\n"
          ]
        }
      ],
      "source": [
        "#!/urs/bin/env python3\n",
        "\n",
        "\"\"\"\n",
        "Make predictions for higher-order soliton and supercontinuum spectral\n",
        "and temporal evolutions.Normalized NLSE, GNLSE and multimode GNLSE have been\n",
        "added.\n",
        "--salmelal--\n",
        "\n",
        "Lauri Salmela\n",
        "lauri.salmela@tuni.fi\n",
        "Tampere University, 2020\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from matplotlib import pyplot as plt\n",
        "import scipy.io as sio\n",
        "import time\n",
        "import sys\n",
        "\n",
        "# from load_data import *\n",
        "# from make_RNN_model import *\n",
        "# from pred_evo import *\n",
        "# from utils import plot_history\n",
        "\n",
        "##########################\n",
        "# mytime = time of indian timezone\n",
        "import datetime\n",
        "now_utc = datetime.datetime.utcnow()\n",
        "IST = datetime.timezone(datetime.timedelta(hours=5, minutes=30))\n",
        "now_ist = now_utc.astimezone(IST)\n",
        "mytime = now_ist.strftime('%H:%M-%Y-%m-%d')\n",
        "#####################\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "\tnp.random.seed(123)  # for reproducibility\n",
        "\n",
        "\tprint(sys.version)\n",
        "\n",
        "\tadd_time = 1  # add time stamp for saved results. Yes (1), No (0)\n",
        "\n",
        "\t# select data file\n",
        "\t#filename = 'simulations/HOS_NLSE_time_145.mat' # train_evo=2900, test_evo=100, steps=101, i_x=145\n",
        "\t#filename = 'simulations/HOS_NLSE_spec_126.mat' # train_evo=2900, test_evo=100, steps=101, i_x=145\n",
        "\t#filename = 'simulations/HOS_expt_time_151.mat' # train_evo=2899, test_evo=100, steps=110, i_x=151\n",
        "\t#filename = 'simulations/HOS_expt_spec_126.mat' # train_evo=2899, test_evo=100, steps=110, i_x=126\n",
        "\t#filename = 'simulations/SC_time_276.mat' # train_evo=1250, test_evo=50, steps=200, i_x=276\n",
        "\t#filename = 'simulations/SC_spec_251.mat' # train_evo=1250, test_evo=50, steps=200, i_x=251\n",
        "\t#filename = 'simulations/norm_NLSE_time_256.mat' # train_evo=950, test_evo=50, steps=101, i_x=256\n",
        "\tfilename = '/content/drive/MyDrive/RNN/data.mat' # train_evo=950, test_evo=50, steps=101, i_x=128\n",
        "\t#\n",
        "\t#filename = 'simulations/chirped_NLSE_time_256.mat' # train_evo=5900, test_evo=100, steps=101, i_x=256, added_params=10\n",
        "\t#filename = 'simulations/norm_GNLSE_spec_132.mat' # train_evo=11800, test_evo=200, steps=51, i_x=132, added_params=10\n",
        "\t#filename = 'simulations/MMGNLSE_spec_301.mat' # train_evo=950, test_evo=50, steps=100, i_x=256, added_params=25\n",
        "\n",
        "\n",
        "\t# define samples for training and testing, and the number of propagation\n",
        "\t# steps in the evolution\n",
        "\ttrain_evo, test_evo, steps = 950, 50, 101\n",
        "\n",
        "\t# define the number of added parameters for chirped_NLSE_time_256 (10),\n",
        "\t# norm_GNLSE_spec_132 (10) and MMGNLSE_spec_301 (25). 0 for other cases.\n",
        "\tadded_params = 0\n",
        "\n",
        "\twindow_size = 10 # RNN window size\n",
        "\n",
        "\t# load data\n",
        "\ti_x, X_train, X_test, Y_train, Y_test = load_data(filename, train_evo,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t  test_evo, steps,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t  window_size,'dBm') # max/dBm\n",
        "\n",
        "\t# load_data_expt is used with HOS_expt_time_151 and HOS_expt_spec_126\n",
        "\t#i_x, X_train, X_test, Y_train, Y_test = load_data_expt(filename, train_evo,\n",
        "\t#\t\t\t\t\t\t\t\t\t\t\t\t\t   test_evo, steps,\n",
        "\t#\t\t\t\t\t\t\t\t\t\t\t\t\t   window_size,'max') # max/dBm\n",
        "\n",
        "\t# load_data_addP is used with chirped_NLSE_time_256, norm_GNLSE_spec_132\n",
        "\t# and MMGNLSE_spec_301\n",
        "\t#i_x, X_train, X_test, Y_train, Y_test = load_data_addP(filename, train_evo,\n",
        "\t#\t\t\t\t\t\t\t\t\t\t\t\t\t   test_evo, steps,\n",
        "\t#\t\t\t\t\t\t\t\t\t\t\t\t\t   window_size,\n",
        "\t#\t\t\t\t\t\t\t\t\t\t\t\t\t   added_params, 'maxC') # maxC/dBmQ/dBmCC\n",
        "\n",
        "\tprint(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
        "\tprint(\"READY...\")\n",
        " \n",
        "\tlocation = '/content/drive/MyDrive/RNN/exp/netsEvo_GRU13:07-2023-04-26.h5'\n",
        "\tdetail = \"adam+2dense-\"\n",
        "\tmodel_type = \"GRU\"\n",
        "\tif(\"LSTM\" in location):\n",
        "\t\tmodel_type = \"LSTM\"\n",
        "\telif(\"biLSTM\" in location):\n",
        "\t\tmodel_type = \"biLSTM\"\n",
        "\t\t\n",
        "\t#model = load_model('nets/HOS_NLSE_time_145_60e.h5')\n",
        "\t#model = load_model('nets/HOS_NLSE_spec_126_80e.h5')\n",
        "\t#model = load_model('nets/HOS_NLSE_spec_lin_126_120e.h5')\n",
        "\t#model = load_model('nets/HOS_expt_time_151_60e.h5')\n",
        "\t#model = load_model('nets/HOS_expt_spec_126_80e.h5')\n",
        "\t#model = load_model('nets/HOS_expt_spec_lin_126_120e.h5')\n",
        "\t#model = load_model('nets/SC_time_276_120e.h5')\n",
        "\t#model = load_model('nets/SC_spec_251_80e.h5')\n",
        "\t#model = load_model('nets/SC_spec_lin_251_100e.h5')\n",
        "\t#model = load_model('nets/norm_NLSE_time_256_80e.h5')\n",
        "\tmodel = load_model(location)\n",
        "\t#model = load_model('nets/chirped_NLSE_time_256_80e.h5')\n",
        "\t#model = load_model('nets/norm_GNLSE_spec_132_80e.h5')\n",
        "\t#model = load_model('nets/MMGNLSE_spec_301_80e.h5')\n",
        "\n",
        "\tmodel.summary()\n",
        "\n",
        "\ttimestr = time.strftime(\"%H:%M--%d-%m-%Y\")\n",
        "\n",
        "\tprint(\"TESTING STEP-WISE...\")\n",
        "\tY_submit = model.predict(X_test)\n",
        "\n",
        "\tprint('saving results...')\n",
        "\tif add_time:\n",
        "\t\tfname = '/content/drive/MyDrive/RNN/exp/predictions/'+ model_type + detail + '_results_' +mytime+ '.mat'\n",
        "\telse:\n",
        "\t\tfname = '/content/drive/MyDrive/RNN/test_results.mat'\n",
        "\tsio.savemat(fname, {'Y_submit':Y_submit, 'Y_test':Y_test, 'steps':steps,\n",
        "\t\t\t\t\t\t'window_size':window_size})\n",
        "\n",
        "\tprint(\"TESTING USING INPUT PROFILE ONLY...\")\n",
        "\n",
        "\tstart = time.time()\n",
        "\tY_submit = pred_evo(model, X_test, test_evo, steps, window_size, i_x)\n",
        "\n",
        "\t# pred_evo_expt is used with HOS_expt_time_151 and HOS_expt_spec_126\n",
        "\t#Y_submit = pred_evo_expt(model, X_test, test_evo, steps, window_size, i_x)\n",
        "\n",
        "\t# pred_evo_expt is used with chirped_NLSE_time_256, norm_GNLSE_spec_132\n",
        "\t# and MMGNLSE_spec_301\n",
        "\t#Y_submit = pred_evo_addP(model, X_test, test_evo, steps, window_size,\n",
        "\t#\t\t\t\t\t\t added_params, i_x)\n",
        "\tend = time.time()\n",
        "\n",
        "\tprint(\"Elapsed time: %f seconds.\" % (end-start))\n",
        "\n",
        "\tprint('saving results from start...')\n",
        "\tif add_time:\n",
        "\t\t'/content/drive/MyDrive/RNN/exp/predictions/'+ model_type + 'test_results' +mytime+ '.mat'\n",
        "\telse:\n",
        "\t\tfname = '/content/drive/MyDrive/RNN/full_test_results.mat'\n",
        "\tsio.savemat(fname, {'Y_submit':Y_submit, 'Y_test':Y_test, 'steps':steps,\n",
        "\t\t\t\t\t\t'window_size':window_size})\n",
        "\tprint(fname + \"  \" + 'all done' )\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1rYePLpwWjy"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}